############################################################
# INTESTAZIONE DA DECIDERE

# Created by:	Elena Ruggiano, Federico Oliva
# Date: 	23-03-2018	

# This library has been developed to automatically tune the parameters of the "analyze_map.bin" algorithm. 
############################################################

# IMPORTS
# All the libraries can be installed by pip except for:
#	ctools: download and install from
#	gammalib: download and install from
#	cscripts: download and install from 

import matplotlib.pyplot as plt
import os 
import ctools
import cscripts
import gammalib
import sys
import argparse
import string
import random
import numpy
import pathlib
import re
import scipy
import itertools as it
from astropy.io import fits
from subprocess import call
from astropy import wcs
import math
from tqdm import tqdm

# SELF BUILT LIBRARIES
import map_creator
import data_analysis

############################################################
# This library aims to create a vast dataset of .fits images containing gamma ray sources. Each map has
# at most one source which is placed within a 0.5 degree circle centered in the pointing coordinates of 
# the telescope 
# The library is organized as follows:
#		1)	function tuning :	this function iterates data_analysis.py with different parameters  
#							minimizing the estimation error			
#		2)	function usage() :  this function calls some methods from data_analysis.py in order to 
#							actually get the estimation										
############################################################

############################################################
# This function aims to tune the parameters of the "analyze_map.bin" algorithm: it just consists of a 
# series of nested loops within which
# all the possible combinations of parameters are tested by calling "data_analysis.py", as it will 
# explained in the "call_data_analysis" 
# function description below.
# Parameters:
#	logfile = logfile where all the data of the maps are stored (previously generated by "recall.py")
#	fits_folder = directory containing alle the .fits files
#	center_type = kind of center estimation (for more details see "analyze_map.bin" reference)
#	sigma_spa_min = minimum possible value for sigma_spa parameter (for more details see 
#				    "analyze_map.bin" reference)
#	sigma_spa_max = maximum possible value for sigma_spa parameter (for more details see 
#				     "analyze_map.bin" reference)
#	accept_level_min = minimum possible value for accept_leve parameterl (for more details see 
#					"analyze_map.bin" reference)
#	accept_level_max = maximum possible value for accept_level parameter (for more details see "
#					   analyze_map.bin" reference)
#	radius_min = minimum possible value for radius parameter (for more details see 
#			      "analyze_map.bin" reference)
#	radius_max = maximum possible value radius parameter (for more details see 
#				"analyze_map.bin" reference)
#	bin_threshold_min = minimum possible value for bin_threshold parameter (for more details see 
#					   "analyze_map.bin" reference)
#	bin_threshold_max = maximum possible value for bin_threshold parameter (for more details see 
#					     "analyze_map.bin" reference)
#	intensity_threshold_min = minimum possible value intensity_threshold parameter (for more 
#						      details see "analyze_map.bin" reference)
#	intensity_threshold_max = maximum possible value for intensity_threshold parameter (for more 
#						       details see "analyze_map.bin" reference)
#	baricenter_dist_min = minimum possible value for baricenter_dist parameter (for more details see 
#						"analyze_map.bin" reference)
#	baricenter_dist_max = maximum possible value for baricenter_dist parameter (for more details 
#						see "analyze_map.bin" reference)
# NB: it's not recommendable to launch tunings with ALL parameters varying as this will dramatically 
# increase compytation time. As far 
# as the used cost function can be assumed as linear with respect to the parameters, 
# it's recommended to tune each of them separately 
############################################################
def tuning(logfile, fits_folder, center_type, sigma_spa_min, sigma_spa_max, accept_level_min, 
accept_level_max, radius_min, radius_max, bin_treshold_min, bin_treshold_max, 
intensity_treshold_min, intensity_treshold_max, baricenter_dist_min, baricenter_dist_max):
	
	# the var "error" will be used to update the best parameter value (cost function to be minimized) 
	# and it therefore needs to be initialised
	error, mean = call_data_analysis(logfile, fits_folder, center_type, str(sigma_spa_min), 
str(accept_level_min), str(radius_min), str(bin_treshold_min), str(intensity_treshold_min), 
str(baricenter_dist_min))

	# tuned parameters initialisation
	sigma_spa_tuned = sigma_spa_min
	accept_level_tuned = accept_level_min
	radius_tuned = radius_min
	bin_treshold_tuned = bin_treshold_min
	intensity_treshold_tuned = intensity_treshold_min	
	baricenter_dist_tuned = baricenter_dist_min

	# nested for loops realisation
	for a in range(int(10*sigma_spa_min), int(10*sigma_spa_max)+1):
		for b in range(int(100*accept_level_min), int(100*accept_level_max)+1):
			for c in range(radius_min,radius_max+1):
				for d in range(bin_treshold_min, bin_treshold_max+1):
					for e in range(int(10*intensity_treshold_min), int(10*intensity_treshold_max)+1):
						for f in range(baricenter_dist_min, baricenter_dist_max+1):

							# current error computation
							tmp_error, tmp_mean = call_data_analysis(logfile, fits_folder, 
center_type, str((a/10)), str((b/100)), str(c), str(d), str((e/10)), str(f))
							print(str(tmp_error) + '\t' + str(error) + '\t' + str(a/10) + '\t' + 
str(b/100) + '\t' + str(c) + '\t' + str(d) + '\t' + str(e/10) + '\t' + str(f) )

							# parameters update
							if (tmp_error < error) or ( (tmp_error == error) and (tmp_mean < mean) ):
								error = tmp_error
								mean = tmp_mean
								sigma_spa_tuned = float(a/10)
								accept_level_tuned = float(b/100)
								radius_tuned = c
								bin_treshold_tuned = d
								intensity_treshold_tuned = float(e/10)	
								baricenter_dist_tuned = f
								
	return sigma_spa_tuned, accept_level_tuned, radius_tuned, bin_treshold_tuned, 
intensity_treshold_tuned, baricenter_dist_tuned
							
############################################################
# this function calls some methods from "data_analysis.py" in order to get the estimation 
# error on the provided benchmark. For more info on the parameters see the reference for 
# "analyze_map.bin"
############################################################
def call_data_analysis(logfile, fits_folder, center_type, sigma_spa, accept_level, radius, 
binary_treshold, intensity_treshold, baricenter_distance):

	# logfile opening and total number of maps retrieving
	log = open(logfile, 'r')
	n_maps = data_analysis.find_n_maps(logfile)

	# image analysis
	[n_sources_array, coord_array] = data_analysis.true_coordinates(logfile, n_maps)
	[est_n_sources_array_b, est_n_sources_array_i, est_n_sources_array_m, est_coord_array_b, 
est_coord_array_i, est_coord_array_m] = data_analysis.switcher(n_maps, center_type, 
sigma_spa, accept_level, radius, binary_treshold, intensity_treshold, baricenter_distance, fits_folder) 
	true_n_sources = int(len(coord_array)/2)

	# statistics evaluation on estimated error
	if center_type.find('b') != -1:
		[diff_array_b, error_b] = data_analysis.difference(n_maps, n_sources_array, 
est_n_sources_array_b, coord_array, est_coord_array_b)
		[mean_dec_b, mean_ra_b, var_dec_b, var_ra_b] = data_analysis.statistics(diff_array_b)
		mean = math.sqrt(mean_dec_b**2 + mean_ra_b**2)
		return error_b, mean
	if center_type.find('i') != -1:
		[diff_array_i, error_i] = data_analysis.difference(n_maps, n_sources_array, 
est_n_sources_array_i, coord_array, est_coord_array_i)
		[mean_dec_i, mean_ra_i, var_dec_i, var_ra_i] = data_analysis.statistics(diff_array_i) 
		mean = math.sqrt(mean_dec_i**2 + mean_ra_i**2)
		return error_i, mean
	if center_type.find('m') != -1:
		[diff_array_m,error_m] = data_analysis.difference(n_maps, n_sources_array, 
est_n_sources_array_m, coord_array, est_coord_array_m) 
		[mean_dec_m, mean_ra_m, var_dec_m, var_ra_m] = data_analysis.statistics(diff_array_m)
		mean = math.sqrt(mean_dec_m**2 + mean_ra_m**2)
		return error_m, mean


if __name__ == "__main__":
    main()
